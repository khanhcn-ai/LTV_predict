{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "1d1acb8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from scipy.optimize import minimize\n",
    "import seaborn as sns\n",
    "import joblib\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "import optuna\n",
    "import lightgbm as lgb\n",
    "import catboost as cb\n",
    "from sklearn.linear_model import ElasticNet\n",
    "import shap\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import logging\n",
    "optuna.logging.set_verbosity(logging.WARNING)\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from numpy.random import dirichlet\n",
    "from pandas.api.types import is_categorical_dtype, is_bool_dtype, is_float_dtype, is_integer_dtype\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from optuna.integration import XGBoostPruningCallback\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', message=\"X does not have valid feature names\")\n",
    "oof_predcit_models = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "8f8081bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_mixup_train_data(X_train_df, y_train_df, augmentation_factor=1.0, random_state=42):\n",
    "    if augmentation_factor <= 0:\n",
    "        return X_train_df.copy(), y_train_df.copy()\n",
    "\n",
    "    X = X_train_df.reset_index(drop=True)\n",
    "    y = y_train_df.reset_index(drop=True)\n",
    "    N = len(X)\n",
    "    if N == 0:\n",
    "        return X.copy(), y.copy()\n",
    "\n",
    "    N_aug = int(N * augmentation_factor)\n",
    "    if N_aug <= 0:\n",
    "        return X.copy(), y.copy()\n",
    "\n",
    "    ohe_groups = []\n",
    "    ohe_cols = set()\n",
    "\n",
    "    rng = np.random.default_rng(random_state)\n",
    "    idx_A = rng.integers(0, N, size=N_aug)\n",
    "    idx_B = (idx_A + (rng.integers(1, N, size=N_aug) if N > 1 else 0)) % max(N, 1)\n",
    "    lam = rng.beta(1.0, 1.0, size=N_aug).reshape(-1, 1)\n",
    "    pickA = (lam.ravel() > 0.5)\n",
    "\n",
    "    cols = list(X.columns)\n",
    "    \n",
    "    float_cols = [c for c in cols if is_float_dtype(X[c].dtype)] \n",
    "    int_cols = [c for c in cols if is_integer_dtype(X[c].dtype)] \n",
    "    bool_cols = [c for c in cols if is_bool_dtype(X[c].dtype)]\n",
    "    \n",
    "    int_cols = [c for c in int_cols if c not in bool_cols and c not in float_cols]\n",
    "    \n",
    "    handled_cols = set(float_cols) | set(int_cols) | set(bool_cols) \n",
    "    other_cols = [c for c in cols if c not in handled_cols]\n",
    "\n",
    "    new_cols = {}\n",
    "\n",
    "    if float_cols:\n",
    "        A = X[float_cols].to_numpy()[idx_A]\n",
    "        B = X[float_cols].to_numpy()[idx_B]\n",
    "        M = lam * A + (1.0 - lam) * B\n",
    "        for j, c in enumerate(float_cols):\n",
    "            new_cols[c] = M[:, j].astype(X[c].dtype, copy=False)\n",
    "\n",
    "    if int_cols:\n",
    "        A = X[int_cols].astype('float64', copy=False).to_numpy()[idx_A]\n",
    "        B = X[int_cols].astype('float64', copy=False).to_numpy()[idx_B]\n",
    "        M = lam * A + (1.0 - lam) * B\n",
    "        R = np.rint(M)\n",
    "        mins = X[int_cols].astype('float64', copy=False).min().to_numpy()\n",
    "        maxs = X[int_cols].astype('float64', copy=False).max().to_numpy()\n",
    "        C = np.clip(R, mins, maxs)\n",
    "        for j, c in enumerate(int_cols):\n",
    "            new_cols[c] = C[:, j].astype(X[c].dtype, copy=False)\n",
    "\n",
    "    if bool_cols:\n",
    "        A = X[bool_cols].to_numpy()[idx_A]\n",
    "        B = X[bool_cols].to_numpy()[idx_B]\n",
    "        M = np.where(pickA[:, None], A, B)\n",
    "        for j, c in enumerate(bool_cols):\n",
    "            new_cols[c] = M[:, j].astype(X[c].dtype, copy=False)\n",
    "\n",
    "    if other_cols:\n",
    "        A = X[other_cols].to_numpy(dtype=object)[idx_A]\n",
    "        B = X[other_cols].to_numpy(dtype=object)[idx_B]\n",
    "        M = np.where(pickA[:, None], A, B)\n",
    "        for j, c in enumerate(other_cols):\n",
    "            new_cols[c] = M[:, j]\n",
    "\n",
    "    X_new = pd.DataFrame({c: new_cols[c] for c in cols}, columns=cols)\n",
    "\n",
    "    yA = y.to_numpy(dtype=np.float64)[idx_A]\n",
    "    yB = y.to_numpy(dtype=np.float64)[idx_B]\n",
    "    y_new = lam * yA + (1.0 - lam) * yB\n",
    "    y_new_df = pd.DataFrame(y_new, columns=y.columns)\n",
    "\n",
    "    X_aug = pd.concat([X, X_new], ignore_index=True)\n",
    "    y_aug = pd.concat([y, y_new_df], ignore_index=True)\n",
    "    return X_aug, y_aug\n",
    "\n",
    "def target_encode_cv(X_train_df, y_train_df, X_test_df, categorical_col, cv):\n",
    "    \n",
    "    X_train_df = X_train_df.reset_index(drop=True)\n",
    "    y_train_df = y_train_df.reset_index(drop=True)\n",
    "    X_test_df = X_test_df.reset_index(drop=True)\n",
    "    \n",
    "    target_col = y_train_df.columns[0]\n",
    "    \n",
    "    oof_encoded = np.zeros(X_train_df.shape[0])\n",
    "    test_encoded = np.zeros(X_test_df.shape[0])\n",
    "    \n",
    "    global_mean = y_train_df[target_col].mean()\n",
    "    \n",
    "    for fold, (train_idx, val_idx) in enumerate(cv.split(X_train_df, y_train_df)):\n",
    "        \n",
    "        X_train_fold = X_train_df.iloc[train_idx]\n",
    "        y_train_fold = y_train_df.iloc[train_idx]\n",
    "        \n",
    "        X_val_fold = X_train_df.iloc[val_idx]\n",
    "        \n",
    "        mean_encoding_map = y_train_fold.groupby(X_train_fold[categorical_col])[target_col].mean()\n",
    "        \n",
    "        oof_encoded[val_idx] = X_val_fold[categorical_col].map(mean_encoding_map).fillna(global_mean).values\n",
    "        \n",
    "        test_encoded_fold = X_test_df[categorical_col].map(mean_encoding_map).fillna(global_mean).values\n",
    "        test_encoded += test_encoded_fold / cv.n_splits\n",
    "\n",
    "    X_train_df[categorical_col] = oof_encoded\n",
    "    X_test_df[categorical_col] = test_encoded\n",
    "    \n",
    "    return X_train_df, X_test_df\n",
    "\n",
    "def generate_oof_elasticnet(X_train_df, y_train_df, X_test_df, cv, random_state=42):\n",
    "    \n",
    "    X_train_df = X_train_df.copy()\n",
    "    X_test_df = X_test_df.copy()\n",
    "\n",
    "    X_train_arr = X_train_df.values\n",
    "    y_train_arr = y_train_df.values.flatten()\n",
    "    X_test_arr = X_test_df.values\n",
    "\n",
    "    oof_predictions = np.zeros(X_train_arr.shape[0])\n",
    "    test_predictions = np.zeros(X_test_arr.shape[0])\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "\n",
    "    for fold, (train_idx, val_idx) in enumerate(cv.split(X_train_arr, y_train_arr)):\n",
    "\n",
    "        model = ElasticNet(alpha=0.1, l1_ratio=0.5, random_state=random_state)\n",
    "\n",
    "        X_train_fold, X_val_fold = X_train_arr[train_idx], X_train_arr[val_idx]\n",
    "        y_train_fold = y_train_arr[train_idx]\n",
    "\n",
    "        X_train_scaled = scaler.fit_transform(X_train_fold)\n",
    "\n",
    "        X_val_scaled = scaler.transform(X_val_fold)\n",
    "        X_test_scaled = scaler.transform(X_test_arr)\n",
    "\n",
    "        model.fit(X_train_scaled, y_train_fold)\n",
    "        oof_predcit_models.append({'fold': fold, 'model': model, 'scaler': X_train_scaled})\n",
    "\n",
    "        oof_predictions[val_idx] = model.predict(X_val_scaled)\n",
    "\n",
    "        test_predictions += model.predict(X_test_scaled) / cv.n_splits\n",
    "\n",
    "    oof_col_name = 'OOF_ElasticNet'\n",
    "\n",
    "    X_train_df[oof_col_name] = oof_predictions\n",
    "    X_test_df[oof_col_name] = test_predictions\n",
    "\n",
    "    return X_train_df, X_test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "3f3d129c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 100)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/2025-01-01_2025-03-02_puzzle_com.twisted.rope.tangle.csv')\n",
    "day = 60\n",
    "\n",
    "df = df[['roas_d0','roas_d1','roas_d2','roas_d3',\n",
    "        'cumulative_revenue_d0','cumulative_revenue_d1','cumulative_revenue_d2','cumulative_revenue_d3',\n",
    "        'daily_revenue_d0','daily_revenue_d1','daily_revenue_d2',\n",
    "        'unique_users_d0','unique_users_d1','unique_users_d2','unique_users_d3','daily_revenue_d3','cost',\n",
    "        'ltv_d0', 'ltv_d1', 'ltv_d2', 'ltv_d3', f'ltv_d{day}']].copy()\n",
    "df['ltv_mean'] = df[['ltv_d0', 'ltv_d1', 'ltv_d2', 'ltv_d3']].mean(axis=1)\n",
    "df['roas_mean'] = df[['roas_d0','roas_d1','roas_d2','roas_d3']].mean(axis=1)\n",
    "df['cumulative_revenue_mean'] = df[['cumulative_revenue_d0','cumulative_revenue_d1','cumulative_revenue_d2','cumulative_revenue_d3']].mean(axis=1)\n",
    "\n",
    "df['ltv_std'] = df[['ltv_d0', 'ltv_d1', 'ltv_d2', 'ltv_d3']].std(axis=1)\n",
    "df['roas_std'] = df[['roas_d0','roas_d1','roas_d2','roas_d3']].std(axis=1)\n",
    "df['cumulative_revenue_std'] = df[['cumulative_revenue_d0','cumulative_revenue_d1','cumulative_revenue_d2','cumulative_revenue_d3']].std(axis=1)\n",
    "\n",
    "df['ltv_growth'] = (df['ltv_d3'] - df['ltv_d0']) / (3 + 1e-9)\n",
    "df['cumulative_revenue_growth'] = df['cumulative_revenue_d3'] - df['cumulative_revenue_d0']\n",
    "\n",
    "df['revenue_acceleration'] = df['daily_revenue_d3'] - df['daily_revenue_d2'] - df['daily_revenue_d1'] + df['daily_revenue_d0']\n",
    "df['user_acceleration'] = df['unique_users_d3'] - df['unique_users_d2'] - df['unique_users_d1'] + df['unique_users_d0']\n",
    "\n",
    "df['roas_trend'] = df['roas_d3'] - df['roas_d0']\n",
    "df['ltv_roas_ratio'] = df['ltv_d3'] / df['roas_d3']\n",
    "\n",
    "df['ltv_slope_d0_d1'] = df['ltv_d1'] - df['ltv_d0']\n",
    "df['ltv_slope_d1_d2'] = df['ltv_d2'] - df['ltv_d1']\n",
    "df['ltv_slope_d2_d3'] = df['ltv_d3'] - df['ltv_d2']\n",
    "df['ARPU_d0'] = df['daily_revenue_d0'] / df['unique_users_d0']\n",
    "df['ARPU_d1'] = df['daily_revenue_d1'] / df['unique_users_d1']\n",
    "df['ARPU_d2'] = df['daily_revenue_d2'] / df['unique_users_d2']\n",
    "df['ARPU_d3'] = df['daily_revenue_d3'] / df['unique_users_d3']\n",
    "df['retention_d1'] = df['unique_users_d1'] / df['unique_users_d0']\n",
    "df['retention_d2'] = df['unique_users_d2'] / df['unique_users_d0']\n",
    "df['retention_d3'] = df['unique_users_d3'] / df['unique_users_d0']\n",
    "\n",
    "df['ltv_acceleration'] = df['ltv_slope_d2_d3'] - df['ltv_slope_d1_d2']\n",
    "df['roas_slope_d0_d1'] = df['roas_d1'] - df['roas_d0']\n",
    "df['roas_slope_d1_d2'] = df['roas_d2'] - df['roas_d1']\n",
    "df['roas_slope_d2_d3'] = df['roas_d3'] - df['roas_d2']\n",
    "df['roas_acceleration'] = df['roas_slope_d2_d3'] - df['roas_slope_d1_d2']\n",
    "df['is_ltv_slowing_down'] = (df['ltv_acceleration'] < 0).astype(int)\n",
    "df['is_roas_slowing_down'] = (df['roas_acceleration'] < 0).astype(int)\n",
    "\n",
    "df['ltv_gain'] = df['ltv_d3'] - df['ltv_d0']\n",
    "df['cumulative_users_d3'] = df['unique_users_d0'] + df['unique_users_d1'] + df['unique_users_d2'] + df['unique_users_d3']\n",
    "df['ARPU_cumulative_d3'] = df['cumulative_revenue_d3'] / df['cumulative_users_d3']\n",
    "df['ARPU_trend'] = (df['daily_revenue_d3'] / (df['unique_users_d3'] + 1e-9)) - (df['daily_revenue_d0'] / (df['unique_users_d0'] + 1e-9))\n",
    "df['Payback_Velocity'] = (df['cumulative_revenue_d3'] / df['cost']) / 4\n",
    "df['Acceleration_Ratio'] = df['revenue_acceleration'] / (df['user_acceleration'] + 1e-9)\n",
    "df['CAC'] = df['cost'] / df['cumulative_users_d3']\n",
    "df['ROAS_CV'] = df['roas_std'] / (df['roas_mean'] + 1e-9)\n",
    "df['ERTI'] = df['cumulative_users_d3'] / df['cost']\n",
    "df['LTV_CAC'] = df['ltv_d3'] / df['CAC']\n",
    "\n",
    "df['daily_to_cumulative_revenue_ratio_d3'] = df['daily_revenue_d3'] / (df['cumulative_revenue_d3'] + 1e-9)\n",
    "df['d0_cohort_value_d3'] = df['cumulative_revenue_d3'] / (df['unique_users_d0'] + 1e-9)\n",
    "df['user_growth_d3_vs_d0'] = df['unique_users_d3'] / (df['unique_users_d0'] + 1e-9)\n",
    "df['cost_per_revenue_d3'] = df['cost'] / (df['cumulative_revenue_d3'] + 1e-9)\n",
    "df['arpu_d3_x_payback'] = df['ARPU_cumulative_d3'] * df['Payback_Velocity']\n",
    "df['LTV_CV'] = df['ltv_std'] / (df['ltv_mean'] + 1e-9)\n",
    "df['LTV_CAC_Trend'] = df['LTV_CAC'] * df['ARPU_trend']\n",
    "df['Cost_LTV_Mean'] = df['cost'] * df['ltv_mean']\n",
    "df['Payback_Accel'] = df['Payback_Velocity'] * df['ltv_acceleration']\n",
    "df['ROAS_Std_Weighted'] = df['roas_std'] * df['LTV_CAC']\n",
    "df['Daily_to_Cumul_LTV'] = df['daily_to_cumulative_revenue_ratio_d3'] * df['ltv_d3']\n",
    "\n",
    "power_cols_base = ['ltv_mean', 'cost', 'LTV_CAC', 'Payback_Velocity', 'ltv_acceleration', 'roas_mean','ARPU_trend']\n",
    "poly_transformer = PolynomialFeatures(degree=2, include_bias=False)\n",
    "X_poly_base = df[power_cols_base]\n",
    "X_poly_transformed = poly_transformer.fit_transform(X_poly_base)\n",
    "new_poly_names = poly_transformer.get_feature_names_out(input_features=power_cols_base)\n",
    "df_poly = pd.DataFrame(X_poly_transformed, columns=new_poly_names, index=df.index)\n",
    "df = pd.concat([df.drop(columns=power_cols_base), df_poly], axis=1)\n",
    "df = df.fillna(0)\n",
    "eps = 1e-9\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "e5984f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['daily_revenue_d0',\n",
    " 'LTV_CAC ARPU_trend',\n",
    " 'ltv_mean Payback_Velocity',\n",
    " 'LTV_CAC roas_mean',\n",
    " 'LTV_CAC Payback_Velocity',\n",
    " 'roas_mean',\n",
    " 'ARPU_cumulative_d3',\n",
    " 'cost Payback_Velocity',\n",
    " 'cost',\n",
    " 'revenue_acceleration',\n",
    " 'LTV_CV',\n",
    " 'Payback_Velocity roas_mean',\n",
    " 'Payback_Velocity',\n",
    " 'cumulative_revenue_d2',\n",
    " 'cumulative_revenue_growth',\n",
    " 'Payback_Velocity ARPU_trend',\n",
    " 'LTV_CAC^2',\n",
    " 'cumulative_users_d3',\n",
    " 'cumulative_revenue_mean',\n",
    " 'Payback_Velocity ltv_acceleration',\n",
    " 'roas_mean^2',\n",
    " 'cost roas_mean',\n",
    " 'cumulative_revenue_std',\n",
    " 'cost_per_revenue_d3',\n",
    " 'cumulative_revenue_d3',\n",
    " 'ltv_mean cost',\n",
    " 'ltv_acceleration roas_mean',\n",
    " 'cumulative_revenue_d1',\n",
    " 'cost^2',\n",
    " 'is_ltv_slowing_down',\n",
    " 'LTV_CAC_Trend',\n",
    " 'Payback_Velocity^2',\n",
    " 'is_roas_slowing_down',\n",
    " 'arpu_d3_x_payback',\n",
    " 'daily_revenue_d2',\n",
    " 'daily_revenue_d3',\n",
    " 'roas_mean ARPU_trend',\n",
    " 'cost LTV_CAC',\n",
    " 'LTV_CAC ltv_acceleration',\n",
    " 'Payback_Accel',\n",
    " 'roas_trend',\n",
    " 'ROAS_Std_Weighted'])#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "baefc610",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_infer = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "66fbcf98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(509, 100)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/raw_2025-04-01_2025-05-31_puzzle_com.twisted.rope.tangle.csv')\n",
    "day = 60\n",
    "\n",
    "df = df[['roas_d0','roas_d1','roas_d2','roas_d3',\n",
    "        'cumulative_revenue_d0','cumulative_revenue_d1','cumulative_revenue_d2','cumulative_revenue_d3',\n",
    "        'daily_revenue_d0','daily_revenue_d1','daily_revenue_d2',\n",
    "        'unique_users_d0','unique_users_d1','unique_users_d2','unique_users_d3','daily_revenue_d3','cost',\n",
    "        'ltv_d0', 'ltv_d1', 'ltv_d2', 'ltv_d3', f'ltv_d{day}']].copy()\n",
    "df['ltv_mean'] = df[['ltv_d0', 'ltv_d1', 'ltv_d2', 'ltv_d3']].mean(axis=1)\n",
    "df['roas_mean'] = df[['roas_d0','roas_d1','roas_d2','roas_d3']].mean(axis=1)\n",
    "df['cumulative_revenue_mean'] = df[['cumulative_revenue_d0','cumulative_revenue_d1','cumulative_revenue_d2','cumulative_revenue_d3']].mean(axis=1)\n",
    "\n",
    "df['ltv_std'] = df[['ltv_d0', 'ltv_d1', 'ltv_d2', 'ltv_d3']].std(axis=1)\n",
    "df['roas_std'] = df[['roas_d0','roas_d1','roas_d2','roas_d3']].std(axis=1)\n",
    "df['cumulative_revenue_std'] = df[['cumulative_revenue_d0','cumulative_revenue_d1','cumulative_revenue_d2','cumulative_revenue_d3']].std(axis=1)\n",
    "\n",
    "df['ltv_growth'] = (df['ltv_d3'] - df['ltv_d0']) / (3 + 1e-9)\n",
    "df['cumulative_revenue_growth'] = df['cumulative_revenue_d3'] - df['cumulative_revenue_d0']\n",
    "\n",
    "df['revenue_acceleration'] = df['daily_revenue_d3'] - df['daily_revenue_d2'] - df['daily_revenue_d1'] + df['daily_revenue_d0']\n",
    "df['user_acceleration'] = df['unique_users_d3'] - df['unique_users_d2'] - df['unique_users_d1'] + df['unique_users_d0']\n",
    "\n",
    "df['roas_trend'] = df['roas_d3'] - df['roas_d0']\n",
    "df['ltv_roas_ratio'] = df['ltv_d3'] / df['roas_d3']\n",
    "\n",
    "df['ltv_slope_d0_d1'] = df['ltv_d1'] - df['ltv_d0']\n",
    "df['ltv_slope_d1_d2'] = df['ltv_d2'] - df['ltv_d1']\n",
    "df['ltv_slope_d2_d3'] = df['ltv_d3'] - df['ltv_d2']\n",
    "df['ARPU_d0'] = df['daily_revenue_d0'] / df['unique_users_d0']\n",
    "df['ARPU_d1'] = df['daily_revenue_d1'] / df['unique_users_d1']\n",
    "df['ARPU_d2'] = df['daily_revenue_d2'] / df['unique_users_d2']\n",
    "df['ARPU_d3'] = df['daily_revenue_d3'] / df['unique_users_d3']\n",
    "df['retention_d1'] = df['unique_users_d1'] / df['unique_users_d0']\n",
    "df['retention_d2'] = df['unique_users_d2'] / df['unique_users_d0']\n",
    "df['retention_d3'] = df['unique_users_d3'] / df['unique_users_d0']\n",
    "\n",
    "df['ltv_acceleration'] = df['ltv_slope_d2_d3'] - df['ltv_slope_d1_d2']\n",
    "df['roas_slope_d0_d1'] = df['roas_d1'] - df['roas_d0']\n",
    "df['roas_slope_d1_d2'] = df['roas_d2'] - df['roas_d1']\n",
    "df['roas_slope_d2_d3'] = df['roas_d3'] - df['roas_d2']\n",
    "df['roas_acceleration'] = df['roas_slope_d2_d3'] - df['roas_slope_d1_d2']\n",
    "df['is_ltv_slowing_down'] = (df['ltv_acceleration'] < 0).astype(int)\n",
    "df['is_roas_slowing_down'] = (df['roas_acceleration'] < 0).astype(int)\n",
    "\n",
    "df['ltv_gain'] = df['ltv_d3'] - df['ltv_d0']\n",
    "df['cumulative_users_d3'] = df['unique_users_d0'] + df['unique_users_d1'] + df['unique_users_d2'] + df['unique_users_d3']\n",
    "df['ARPU_cumulative_d3'] = df['cumulative_revenue_d3'] / df['cumulative_users_d3']\n",
    "df['ARPU_trend'] = (df['daily_revenue_d3'] / (df['unique_users_d3'] + 1e-9)) - (df['daily_revenue_d0'] / (df['unique_users_d0'] + 1e-9))\n",
    "df['Payback_Velocity'] = (df['cumulative_revenue_d3'] / df['cost']) / 4\n",
    "df['Acceleration_Ratio'] = df['revenue_acceleration'] / (df['user_acceleration'] + 1e-9)\n",
    "df['CAC'] = df['cost'] / df['cumulative_users_d3']\n",
    "df['ROAS_CV'] = df['roas_std'] / (df['roas_mean'] + 1e-9)\n",
    "df['ERTI'] = df['cumulative_users_d3'] / df['cost']\n",
    "df['LTV_CAC'] = df['ltv_d3'] / df['CAC']\n",
    "\n",
    "df['daily_to_cumulative_revenue_ratio_d3'] = df['daily_revenue_d3'] / (df['cumulative_revenue_d3'] + 1e-9)\n",
    "df['d0_cohort_value_d3'] = df['cumulative_revenue_d3'] / (df['unique_users_d0'] + 1e-9)\n",
    "df['user_growth_d3_vs_d0'] = df['unique_users_d3'] / (df['unique_users_d0'] + 1e-9)\n",
    "df['cost_per_revenue_d3'] = df['cost'] / (df['cumulative_revenue_d3'] + 1e-9)\n",
    "df['arpu_d3_x_payback'] = df['ARPU_cumulative_d3'] * df['Payback_Velocity']\n",
    "df['LTV_CV'] = df['ltv_std'] / (df['ltv_mean'] + 1e-9)\n",
    "df['LTV_CAC_Trend'] = df['LTV_CAC'] * df['ARPU_trend']\n",
    "df['Cost_LTV_Mean'] = df['cost'] * df['ltv_mean']\n",
    "df['Payback_Accel'] = df['Payback_Velocity'] * df['ltv_acceleration']\n",
    "df['ROAS_Std_Weighted'] = df['roas_std'] * df['LTV_CAC']\n",
    "df['Daily_to_Cumul_LTV'] = df['daily_to_cumulative_revenue_ratio_d3'] * df['ltv_d3']\n",
    "\n",
    "power_cols_base = ['ltv_mean', 'cost', 'LTV_CAC', 'Payback_Velocity', 'ltv_acceleration', 'roas_mean','ARPU_trend']\n",
    "poly_transformer = PolynomialFeatures(degree=2, include_bias=False)\n",
    "X_poly_base = df[power_cols_base]\n",
    "X_poly_transformed = poly_transformer.fit_transform(X_poly_base)\n",
    "new_poly_names = poly_transformer.get_feature_names_out(input_features=power_cols_base)\n",
    "df_poly = pd.DataFrame(X_poly_transformed, columns=new_poly_names, index=df.index)\n",
    "df = pd.concat([df.drop(columns=power_cols_base), df_poly], axis=1)\n",
    "df = df.fillna(0)\n",
    "eps = 1e-9\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "86d92d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['daily_revenue_d0',\n",
    " 'LTV_CAC ARPU_trend',\n",
    " 'ltv_mean Payback_Velocity',\n",
    " 'LTV_CAC roas_mean',\n",
    " 'LTV_CAC Payback_Velocity',\n",
    " 'roas_mean',\n",
    " 'ARPU_cumulative_d3',\n",
    " 'cost Payback_Velocity',\n",
    " 'cost',\n",
    " 'revenue_acceleration',\n",
    " 'LTV_CV',\n",
    " 'Payback_Velocity roas_mean',\n",
    " 'Payback_Velocity',\n",
    " 'cumulative_revenue_d2',\n",
    " 'cumulative_revenue_growth',\n",
    " 'Payback_Velocity ARPU_trend',\n",
    " 'LTV_CAC^2',\n",
    " 'cumulative_users_d3',\n",
    " 'cumulative_revenue_mean',\n",
    " 'Payback_Velocity ltv_acceleration',\n",
    " 'roas_mean^2',\n",
    " 'cost roas_mean',\n",
    " 'cumulative_revenue_std',\n",
    " 'cost_per_revenue_d3',\n",
    " 'cumulative_revenue_d3',\n",
    " 'ltv_mean cost',\n",
    " 'ltv_acceleration roas_mean',\n",
    " 'cumulative_revenue_d1',\n",
    " 'cost^2',\n",
    " 'is_ltv_slowing_down',\n",
    " 'LTV_CAC_Trend',\n",
    " 'Payback_Velocity^2',\n",
    " 'is_roas_slowing_down',\n",
    " 'arpu_d3_x_payback',\n",
    " 'daily_revenue_d2',\n",
    " 'daily_revenue_d3',\n",
    " 'roas_mean ARPU_trend',\n",
    " 'cost LTV_CAC',\n",
    " 'LTV_CAC ltv_acceleration',\n",
    " 'Payback_Accel',\n",
    " 'roas_trend',\n",
    " 'ROAS_Std_Weighted'])#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "135bbf5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df.drop(columns=[f'ltv_d{day}']).columns.tolist()\n",
    "target = f'ltv_d{day}'\n",
    "\n",
    "X = df[features]\n",
    "y = df[[target]]\n",
    "X_infer = df_infer[features]\n",
    "y_infer = df_infer[[target]]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train, y_train = apply_mixup_train_data(X_train, y_train, augmentation_factor=1.0, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "22f83736",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = X_train.columns.tolist()\n",
    "preprocessor_X = PowerTransformer(method='yeo-johnson', standardize=False)\n",
    "preprocessor_y = PowerTransformer(method='yeo-johnson', standardize=False)\n",
    "\n",
    "X_train_transformed = pd.DataFrame(preprocessor_X.fit_transform(X_train), columns=features)\n",
    "X_test_transformed = pd.DataFrame(preprocessor_X.transform(X_test), columns=features)\n",
    "X_infer_transformed = pd.DataFrame(preprocessor_X.transform(X_infer), columns=features)\n",
    "y_train_transformed = pd.DataFrame(preprocessor_y.fit_transform(y_train), columns=[f'ltv_d{day}'])\n",
    "y_test_transformed = pd.DataFrame(preprocessor_y.transform(y_test), columns=[f'ltv_d{day}'])\n",
    "y_infer_transformed = pd.DataFrame(preprocessor_y.transform(y_infer), columns=[f'ltv_d{day}'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "2976364f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(814, 57)\n",
      "(102, 57)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_transformed.shape)\n",
    "print(X_test_transformed.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "e47078e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_transformed.reset_index(drop=True, inplace=True)\n",
    "y_test_transformed.reset_index(drop=True, inplace=True)\n",
    "X_test_transformed.reset_index(drop=True, inplace=True)\n",
    "y_train_transformed.reset_index(drop=True, inplace=True)\n",
    "X_train_transformed, X_test_transformed = generate_oof_elasticnet(X_train_transformed, y_train_transformed, X_test_transformed, cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "952faa6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(814, 58)\n",
      "(102, 58)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_transformed.shape)\n",
    "print(X_test_transformed.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5509a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nae_eval_metric(y_pred, y_true):\n",
    "    y_true_transformed = y_true.get_label()\n",
    "    y_pred_transformed = y_pred\n",
    "\n",
    "    y_true_original = preprocessor_y.inverse_transform(\n",
    "        y_true_transformed.reshape(-1, 1)\n",
    "    ).flatten()\n",
    "    \n",
    "    y_pred_original = preprocessor_y.inverse_transform(\n",
    "        y_pred_transformed.reshape(-1, 1)\n",
    "    ).flatten()\n",
    "    \n",
    "    nae = np.mean(\n",
    "        np.abs(y_true_original - y_pred_original) / (np.abs(y_true_original)+ eps)\n",
    "    )\n",
    "    \n",
    "    return 'custom_nae', nae * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ee6a1fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_train_xgboost = xgb.DMatrix(X_train_transformed, label=y_train_transformed)\n",
    "d_train_lightgbm = lgb.Dataset(X_train_transformed, label=y_train_transformed, params={'feature_pre_filter': False})\n",
    "d_train_catboost = cb.Pool(X_train_transformed, label=y_train_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e10145",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_xgboost(trial, d_train):\n",
    "    \n",
    "    param = {\n",
    "        'objective': 'reg:absoluteerror',\n",
    "        'random_state': 42,\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.005, 0.2, log=True),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 9),\n",
    "        'lambda': trial.suggest_float('lambda', 1e-8, 10.0, log=True),\n",
    "        'alpha': trial.suggest_float('alpha', 1e-8, 10.0, log=True),\n",
    "        'min_child_weight': trial.suggest_int('min_child_weight', 1, 5),\n",
    "        'subsample': trial.suggest_float('subsample', 0.5, 0.95),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 0.9)\n",
    "    }\n",
    "\n",
    "    cv_results = xgb.cv(\n",
    "        params=param,\n",
    "        dtrain=d_train,\n",
    "        num_boost_round=1000,\n",
    "        nfold=5,\n",
    "        custom_metric=nae_eval_metric,\n",
    "        maximize=False,\n",
    "        as_pandas=True,\n",
    "        early_stopping_rounds=30\n",
    "    )\n",
    "    best_iteration = cv_results['test-custom_nae-mean'].argmin()\n",
    "    best_nae = cv_results['test-custom_nae-mean'].min()\n",
    "    n_estimators_optimal = best_iteration + 1\n",
    "    \n",
    "    trial.set_user_attr('n_estimators_optimal', n_estimators_optimal)    \n",
    "    return best_nae\n",
    "\n",
    "def objective_lightgbm_function(trial):\n",
    "    \n",
    "    param = {\n",
    "        'objective': 'regression_l1',\n",
    "        'metric': 'l1',\n",
    "        'random_state': 42,\n",
    "        'force_col_wise': True,\n",
    "        'feature_pre_filter': False, \n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.1, log=True),\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 15, 40),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 11),\n",
    "        'min_data_in_leaf': trial.suggest_int('min_data_in_leaf', 10, 50),\n",
    "        'lambda_l1': trial.suggest_float('lambda_l1', 1e-8, 10.0, log=True),\n",
    "        'lambda_l2': trial.suggest_float('lambda_l2', 1e-8, 10.0, log=True),\n",
    "        'verbose': -1\n",
    "    }\n",
    "    \n",
    "    cv_results = lgb.cv(\n",
    "        params=param,\n",
    "        train_set=d_train_lightgbm,\n",
    "        num_boost_round=2000,\n",
    "        nfold=5,\n",
    "        stratified=False,\n",
    "        callbacks=[lgb.early_stopping(30, verbose=False)],\n",
    "        seed=42\n",
    "    )\n",
    "    \n",
    "    best_iteration = cv_results['valid l1-mean'].index(min(cv_results['valid l1-mean']))\n",
    "    best_mae = min(cv_results['valid l1-mean'])\n",
    "\n",
    "    n_estimators_optimal = best_iteration + 1\n",
    "    trial.set_user_attr('n_estimators_optimal', n_estimators_optimal) \n",
    "    \n",
    "    return best_mae\n",
    "\n",
    "def objective_catboost_function(trial):\n",
    "    bootstrap_type = trial.suggest_categorical('bootstrap_type', ['Bayesian', 'Bernoulli', 'MVS'])\n",
    "    param = {\n",
    "        'loss_function': 'MAE',\n",
    "        'eval_metric': 'MAE',\n",
    "        'random_seed': 42,\n",
    "        'bootstrap_type': bootstrap_type,\n",
    "        'verbose': -1,\n",
    "        'task_type': 'GPU',\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.005, 0.2, log=True),\n",
    "        'depth': trial.suggest_int('max_depth', 3, 9),\n",
    "        'l2_leaf_reg': trial.suggest_float('lambda', 1e-8, 10.0, log=True),\n",
    "        'min_data_in_leaf': trial.suggest_int('min_child_weight', 1, 5),\n",
    "    }\n",
    "\n",
    "    if bootstrap_type == 'Bernoulli':\n",
    "        param['subsample'] = trial.suggest_float('subsample', 0.5, 0.95)\n",
    "\n",
    "    pool_cv = cb.Pool(\n",
    "        data=X_train_transformed, \n",
    "        label=y_train_transformed\n",
    "    )\n",
    "    \n",
    "    cv_results = cb.cv(\n",
    "        pool=pool_cv,\n",
    "        params=param,\n",
    "        fold_count=5,\n",
    "        iterations=1000,\n",
    "        early_stopping_rounds=30,\n",
    "        shuffle=True,\n",
    "        verbose=False,\n",
    "        seed=42\n",
    "    )\n",
    "\n",
    "    metric_key = 'test-MAE-mean'\n",
    "    \n",
    "    best_iteration = cv_results[metric_key].argmin()\n",
    "    best_loss = cv_results[metric_key].min()\n",
    "    n_estimators_optimal = best_iteration + 1\n",
    "    \n",
    "    trial.set_user_attr('n_estimators_optimal', n_estimators_optimal) \n",
    "    \n",
    "    return best_loss\n",
    "\n",
    "def objective_xgboost(trial, d_train):\n",
    "    \n",
    "    param = {\n",
    "        'objective': 'reg:absoluteerror',\n",
    "        'random_state': 42,\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.005, 0.2, log=True),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 9),\n",
    "        'lambda': trial.suggest_float('lambda', 1e-8, 10.0, log=True),\n",
    "        'alpha': trial.suggest_float('alpha', 1e-8, 10.0, log=True),\n",
    "        'min_child_weight': trial.suggest_int('min_child_weight', 1, 5),\n",
    "        'subsample': trial.suggest_float('subsample', 0.5, 0.95),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 0.9)\n",
    "    }\n",
    "\n",
    "    cv_results = xgb.cv(\n",
    "        params=param,\n",
    "        dtrain=d_train,\n",
    "        num_boost_round=1000,\n",
    "        nfold=5,\n",
    "        custom_metric=nae_eval_metric,\n",
    "        maximize=False,\n",
    "        as_pandas=True,\n",
    "        early_stopping_rounds=30\n",
    "    )\n",
    "    best_iteration = cv_results['test-custom_nae-mean'].argmin()\n",
    "    best_nae = cv_results['test-custom_nae-mean'].min()\n",
    "    n_estimators_optimal = best_iteration + 1\n",
    "    \n",
    "    trial.set_user_attr('n_estimators_optimal', n_estimators_optimal)    \n",
    "    return best_nae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4897159b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bba2849f0ab4400799046894ac62d86c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/60 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "study_xgboost = optuna.create_study(direction='minimize', pruner=optuna.pruners.MedianPruner(n_startup_trials=5, n_warmup_steps=30))\n",
    "study_xgboost.optimize(objective_xgboost_function, n_trials=60, show_progress_bar=True)\n",
    "best_xgboost_n_estimators = study_xgboost.best_trial.user_attrs.get('n_estimators_optimal') \n",
    "final_xgboost_params = study_xgboost.best_params.copy()\n",
    "final_xgboost_params['n_estimators'] = best_xgboost_n_estimators\n",
    "final_xgboost_params['objective'] = 'reg:absoluteerror'\n",
    "best_xgb_model = xgb.XGBRegressor(**final_xgboost_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "baff200d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cecfa6b827e84d30b4ec563b52f2fd37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/60 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "study_lightgbm = optuna.create_study(direction='minimize', pruner=optuna.pruners.MedianPruner(n_startup_trials=5, n_warmup_steps=30),study_name='LightGBM_Hyperparameter_Tuning')\n",
    "study_lightgbm.optimize(objective_lightgbm_function, n_trials=60, show_progress_bar=True)\n",
    "best_lgbm_n_estimators = study_lightgbm.best_trial.user_attrs.get('n_estimators_optimal')\n",
    "final_lightgbm_params = study_lightgbm.best_params.copy()\n",
    "final_lightgbm_params['objective'] = 'regression_l1'\n",
    "final_lightgbm_params['n_estimators'] = best_lgbm_n_estimators\n",
    "final_lightgbm_params['metric'] = 'custom'\n",
    "final_lightgbm_params['random_state'] = 42\n",
    "final_lightgbm_params['boosting_type'] = 'gbdt'\n",
    "best_lgbm_model = lgb.LGBMRegressor(**final_lightgbm_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c3bc9545",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5096e5f869ae40e08e32a02f8346230b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/60 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Default metric period is 5 because MAE is/are not implemented for GPU\n",
      "Warning: Overfitting detector is active, thus evaluation metric is calculated on every iteration. 'metric_period' is ignored for evaluation metric.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on fold [0/5]\n",
      "bestTest = 0.02635992085\n",
      "bestIteration = 6\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.02416300627\n",
      "bestIteration = 9\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.02928469371\n",
      "bestIteration = 6\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.02584384848\n",
      "bestIteration = 6\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.02882600125\n",
      "bestIteration = 7\n",
      "Training on fold [0/5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Default metric period is 5 because MAE is/are not implemented for GPU\n",
      "Warning: Overfitting detector is active, thus evaluation metric is calculated on every iteration. 'metric_period' is ignored for evaluation metric.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bestTest = 0.02305503418\n",
      "bestIteration = 8\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.02442289569\n",
      "bestIteration = 11\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.0216838392\n",
      "bestIteration = 8\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.02479043036\n",
      "bestIteration = 8\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.02331791984\n",
      "bestIteration = 8\n",
      "Training on fold [0/5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Default metric period is 5 because MAE is/are not implemented for GPU\n",
      "Warning: Overfitting detector is active, thus evaluation metric is calculated on every iteration. 'metric_period' is ignored for evaluation metric.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bestTest = 0.01539386562\n",
      "bestIteration = 271\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.0153224439\n",
      "bestIteration = 338\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.01281589233\n",
      "bestIteration = 254\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.01531942637\n",
      "bestIteration = 362\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.01467921263\n",
      "bestIteration = 439\n",
      "Training on fold [0/5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Default metric period is 5 because MAE is/are not implemented for GPU\n",
      "Warning: Overfitting detector is active, thus evaluation metric is calculated on every iteration. 'metric_period' is ignored for evaluation metric.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bestTest = 0.01496741816\n",
      "bestIteration = 73\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.01574320588\n",
      "bestIteration = 92\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.01318981896\n",
      "bestIteration = 104\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.01658039298\n",
      "bestIteration = 103\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.01541655888\n",
      "bestIteration = 115\n",
      "Training on fold [0/5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Default metric period is 5 because MAE is/are not implemented for GPU\n",
      "Warning: Overfitting detector is active, thus evaluation metric is calculated on every iteration. 'metric_period' is ignored for evaluation metric.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bestTest = 0.01654513043\n",
      "bestIteration = 29\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.01863095219\n",
      "bestIteration = 30\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.01556934462\n",
      "bestIteration = 32\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.01732237354\n",
      "bestIteration = 35\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.01902956138\n",
      "bestIteration = 46\n",
      "Training on fold [0/5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Default metric period is 5 because MAE is/are not implemented for GPU\n",
      "Warning: Overfitting detector is active, thus evaluation metric is calculated on every iteration. 'metric_period' is ignored for evaluation metric.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bestTest = 0.02757333978\n",
      "bestIteration = 5\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.02618144919\n",
      "bestIteration = 5\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.02755388599\n",
      "bestIteration = 5\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.03396521024\n",
      "bestIteration = 6\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.02829943174\n",
      "bestIteration = 5\n",
      "Training on fold [0/5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Default metric period is 5 because MAE is/are not implemented for GPU\n",
      "Warning: Overfitting detector is active, thus evaluation metric is calculated on every iteration. 'metric_period' is ignored for evaluation metric.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bestTest = 0.02317228054\n",
      "bestIteration = 8\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.02266685656\n",
      "bestIteration = 9\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.02278012293\n",
      "bestIteration = 9\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.02418216167\n",
      "bestIteration = 10\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.02348162804\n",
      "bestIteration = 9\n",
      "Training on fold [0/5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Default metric period is 5 because MAE is/are not implemented for GPU\n",
      "Warning: Overfitting detector is active, thus evaluation metric is calculated on every iteration. 'metric_period' is ignored for evaluation metric.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bestTest = 0.01845949559\n",
      "bestIteration = 31\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.01909450519\n",
      "bestIteration = 22\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.01771913716\n",
      "bestIteration = 26\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.02042119342\n",
      "bestIteration = 22\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.01931242295\n",
      "bestIteration = 26\n",
      "Training on fold [0/5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Default metric period is 5 because MAE is/are not implemented for GPU\n",
      "Warning: Overfitting detector is active, thus evaluation metric is calculated on every iteration. 'metric_period' is ignored for evaluation metric.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bestTest = 0.01593785637\n",
      "bestIteration = 82\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.01673447135\n",
      "bestIteration = 59\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.01430296313\n",
      "bestIteration = 61\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.01688184329\n",
      "bestIteration = 90\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.01660973643\n",
      "bestIteration = 67\n",
      "Training on fold [0/5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Default metric period is 5 because MAE is/are not implemented for GPU\n",
      "Warning: Overfitting detector is active, thus evaluation metric is calculated on every iteration. 'metric_period' is ignored for evaluation metric.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bestTest = 0.01496516854\n",
      "bestIteration = 150\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.0158497746\n",
      "bestIteration = 167\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.01387138601\n",
      "bestIteration = 169\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.01590326959\n",
      "bestIteration = 180\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.01564550253\n",
      "bestIteration = 183\n",
      "Training on fold [0/5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Default metric period is 5 because MAE is/are not implemented for GPU\n",
      "Warning: Overfitting detector is active, thus evaluation metric is calculated on every iteration. 'metric_period' is ignored for evaluation metric.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bestTest = 0.01407973167\n",
      "bestIteration = 449\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.01602892495\n",
      "bestIteration = 278\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.01301993622\n",
      "bestIteration = 318\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.01506696011\n",
      "bestIteration = 359\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.01509108072\n",
      "bestIteration = 378\n",
      "Training on fold [0/5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Default metric period is 5 because MAE is/are not implemented for GPU\n",
      "Warning: Overfitting detector is active, thus evaluation metric is calculated on every iteration. 'metric_period' is ignored for evaluation metric.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bestTest = 0.01477012166\n",
      "bestIteration = 429\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.01599058783\n",
      "bestIteration = 240\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.01349449743\n",
      "bestIteration = 270\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.01404724823\n",
      "bestIteration = 473\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.0148355534\n",
      "bestIteration = 292\n",
      "Training on fold [0/5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Default metric period is 5 because MAE is/are not implemented for GPU\n",
      "Warning: Overfitting detector is active, thus evaluation metric is calculated on every iteration. 'metric_period' is ignored for evaluation metric.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bestTest = 0.01563423543\n",
      "bestIteration = 273\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.01669126786\n",
      "bestIteration = 260\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.01322537551\n",
      "bestIteration = 309\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.01706583222\n",
      "bestIteration = 193\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.01536101176\n",
      "bestIteration = 333\n",
      "Training on fold [0/5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Default metric period is 5 because MAE is/are not implemented for GPU\n",
      "Warning: Overfitting detector is active, thus evaluation metric is calculated on every iteration. 'metric_period' is ignored for evaluation metric.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bestTest = 0.01497430743\n",
      "bestIteration = 74\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.01642439702\n",
      "bestIteration = 66\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.01431076366\n",
      "bestIteration = 63\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.01661155999\n",
      "bestIteration = 65\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.01520309183\n",
      "bestIteration = 49\n",
      "Training on fold [0/5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Default metric period is 5 because MAE is/are not implemented for GPU\n",
      "Warning: Overfitting detector is active, thus evaluation metric is calculated on every iteration. 'metric_period' is ignored for evaluation metric.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bestTest = 0.01877927634\n",
      "bestIteration = 25\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.01963871242\n",
      "bestIteration = 42\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.01563734803\n",
      "bestIteration = 19\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.01944599415\n",
      "bestIteration = 33\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.01875817187\n",
      "bestIteration = 17\n",
      "Training on fold [0/5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Default metric period is 5 because MAE is/are not implemented for GPU\n",
      "Warning: Overfitting detector is active, thus evaluation metric is calculated on every iteration. 'metric_period' is ignored for evaluation metric.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bestTest = 0.01497079697\n",
      "bestIteration = 177\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.01491919032\n",
      "bestIteration = 177\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.01307915032\n",
      "bestIteration = 128\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.01526354427\n",
      "bestIteration = 198\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.01549664839\n",
      "bestIteration = 204\n",
      "Training on fold [0/5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Default metric period is 5 because MAE is/are not implemented for GPU\n",
      "Warning: Overfitting detector is active, thus evaluation metric is calculated on every iteration. 'metric_period' is ignored for evaluation metric.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bestTest = 0.01558671115\n",
      "bestIteration = 70\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.01544263612\n",
      "bestIteration = 88\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.01343646956\n",
      "bestIteration = 98\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.01426286346\n",
      "bestIteration = 266\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.01529891991\n",
      "bestIteration = 75\n",
      "Training on fold [0/5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Default metric period is 5 because MAE is/are not implemented for GPU\n",
      "Warning: Overfitting detector is active, thus evaluation metric is calculated on every iteration. 'metric_period' is ignored for evaluation metric.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bestTest = 0.03654484369\n",
      "bestIteration = 5\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.03364687024\n",
      "bestIteration = 3\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.03408703482\n",
      "bestIteration = 7\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.03965280685\n",
      "bestIteration = 3\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.04232975877\n",
      "bestIteration = 3\n",
      "Training on fold [0/5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Default metric period is 5 because MAE is/are not implemented for GPU\n",
      "Warning: Overfitting detector is active, thus evaluation metric is calculated on every iteration. 'metric_period' is ignored for evaluation metric.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bestTest = 0.01496257372\n",
      "bestIteration = 144\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.01491460625\n",
      "bestIteration = 212\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.01328843942\n",
      "bestIteration = 172\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.0150891345\n",
      "bestIteration = 220\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.01462124895\n",
      "bestIteration = 262\n",
      "Training on fold [0/5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Default metric period is 5 because MAE is/are not implemented for GPU\n",
      "Warning: Overfitting detector is active, thus evaluation metric is calculated on every iteration. 'metric_period' is ignored for evaluation metric.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bestTest = 0.01548973914\n",
      "bestIteration = 132\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.01508426081\n",
      "bestIteration = 241\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.01288177631\n",
      "bestIteration = 224\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.01480166897\n",
      "bestIteration = 222\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.01487735466\n",
      "bestIteration = 158\n",
      "Training on fold [0/5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Default metric period is 5 because MAE is/are not implemented for GPU\n",
      "Warning: Overfitting detector is active, thus evaluation metric is calculated on every iteration. 'metric_period' is ignored for evaluation metric.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bestTest = 0.01578624994\n",
      "bestIteration = 45\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.01639835235\n",
      "bestIteration = 129\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.01455992277\n",
      "bestIteration = 43\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.01499723949\n",
      "bestIteration = 78\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.01668067332\n",
      "bestIteration = 49\n",
      "Training on fold [0/5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Default metric period is 5 because MAE is/are not implemented for GPU\n",
      "Warning: Overfitting detector is active, thus evaluation metric is calculated on every iteration. 'metric_period' is ignored for evaluation metric.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bestTest = 0.01451444333\n",
      "bestIteration = 351\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.01501293124\n",
      "bestIteration = 255\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.01309589374\n",
      "bestIteration = 192\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.01466370507\n",
      "bestIteration = 260\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.01484073533\n",
      "bestIteration = 307\n",
      "Training on fold [0/5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Default metric period is 5 because MAE is/are not implemented for GPU\n",
      "Warning: Overfitting detector is active, thus evaluation metric is calculated on every iteration. 'metric_period' is ignored for evaluation metric.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bestTest = 0.01478760959\n",
      "bestIteration = 115\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.01589742029\n",
      "bestIteration = 162\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.01355450431\n",
      "bestIteration = 143\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.01583759331\n",
      "bestIteration = 168\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.01489965857\n",
      "bestIteration = 264\n",
      "Training on fold [0/5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Default metric period is 5 because MAE is/are not implemented for GPU\n",
      "Warning: Overfitting detector is active, thus evaluation metric is calculated on every iteration. 'metric_period' is ignored for evaluation metric.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bestTest = 0.01567906982\n",
      "bestIteration = 85\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.01576001074\n",
      "bestIteration = 94\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.01340063803\n",
      "bestIteration = 163\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.01467519596\n",
      "bestIteration = 251\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.01526659506\n",
      "bestIteration = 144\n",
      "Training on fold [0/5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Default metric period is 5 because MAE is/are not implemented for GPU\n",
      "Warning: Overfitting detector is active, thus evaluation metric is calculated on every iteration. 'metric_period' is ignored for evaluation metric.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bestTest = 0.01404838035\n",
      "bestIteration = 180\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.01522175959\n",
      "bestIteration = 142\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.01353465999\n",
      "bestIteration = 146\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.01535565721\n",
      "bestIteration = 203\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.01493798951\n",
      "bestIteration = 177\n",
      "Training on fold [0/5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Default metric period is 5 because MAE is/are not implemented for GPU\n",
      "Warning: Overfitting detector is active, thus evaluation metric is calculated on every iteration. 'metric_period' is ignored for evaluation metric.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bestTest = 0.01575062465\n",
      "bestIteration = 86\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.01674947124\n",
      "bestIteration = 81\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.01513352131\n",
      "bestIteration = 59\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.01771635951\n",
      "bestIteration = 70\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.01693275534\n",
      "bestIteration = 70\n",
      "Training on fold [0/5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Default metric period is 5 because MAE is/are not implemented for GPU\n",
      "Warning: Overfitting detector is active, thus evaluation metric is calculated on every iteration. 'metric_period' is ignored for evaluation metric.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bestTest = 0.01461896136\n",
      "bestIteration = 139\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.01447158796\n",
      "bestIteration = 222\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.01294205671\n",
      "bestIteration = 164\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.01485305769\n",
      "bestIteration = 217\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.0151647138\n",
      "bestIteration = 293\n",
      "Training on fold [0/5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Default metric period is 5 because MAE is/are not implemented for GPU\n",
      "Warning: Overfitting detector is active, thus evaluation metric is calculated on every iteration. 'metric_period' is ignored for evaluation metric.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bestTest = 0.01498785341\n",
      "bestIteration = 94\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.0155925546\n",
      "bestIteration = 135\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.01320654629\n",
      "bestIteration = 100\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.01543150943\n",
      "bestIteration = 163\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.01462625133\n",
      "bestIteration = 170\n",
      "Training on fold [0/5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Default metric period is 5 because MAE is/are not implemented for GPU\n",
      "Warning: Overfitting detector is active, thus evaluation metric is calculated on every iteration. 'metric_period' is ignored for evaluation metric.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bestTest = 0.0176377823\n",
      "bestIteration = 21\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.01933111004\n",
      "bestIteration = 19\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.0179969694\n",
      "bestIteration = 20\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.01885277508\n",
      "bestIteration = 18\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.01952626087\n",
      "bestIteration = 16\n",
      "Training on fold [0/5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Default metric period is 5 because MAE is/are not implemented for GPU\n",
      "Warning: Overfitting detector is active, thus evaluation metric is calculated on every iteration. 'metric_period' is ignored for evaluation metric.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bestTest = 0.01585574823\n",
      "bestIteration = 71\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.01558133137\n",
      "bestIteration = 65\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.01336031896\n",
      "bestIteration = 50\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.01427823927\n",
      "bestIteration = 168\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.01600357633\n",
      "bestIteration = 110\n",
      "Training on fold [0/5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Default metric period is 5 because MAE is/are not implemented for GPU\n",
      "Warning: Overfitting detector is active, thus evaluation metric is calculated on every iteration. 'metric_period' is ignored for evaluation metric.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bestTest = 0.01454835143\n",
      "bestIteration = 321\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.01550829484\n",
      "bestIteration = 246\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.01331903452\n",
      "bestIteration = 134\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.01477673595\n",
      "bestIteration = 267\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.01484328435\n",
      "bestIteration = 292\n",
      "Training on fold [0/5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Default metric period is 5 because MAE is/are not implemented for GPU\n",
      "Warning: Overfitting detector is active, thus evaluation metric is calculated on every iteration. 'metric_period' is ignored for evaluation metric.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bestTest = 0.01479120489\n",
      "bestIteration = 155\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.01450285005\n",
      "bestIteration = 187\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.01335966806\n",
      "bestIteration = 163\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.01506064567\n",
      "bestIteration = 235\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.01481881848\n",
      "bestIteration = 177\n",
      "Training on fold [0/5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Default metric period is 5 because MAE is/are not implemented for GPU\n",
      "Warning: Overfitting detector is active, thus evaluation metric is calculated on every iteration. 'metric_period' is ignored for evaluation metric.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bestTest = 0.01380299937\n",
      "bestIteration = 271\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.01517283697\n",
      "bestIteration = 222\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.01374768333\n",
      "bestIteration = 200\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.01521034767\n",
      "bestIteration = 215\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.01450598093\n",
      "bestIteration = 251\n",
      "Training on fold [0/5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Default metric period is 5 because MAE is/are not implemented for GPU\n",
      "Warning: Overfitting detector is active, thus evaluation metric is calculated on every iteration. 'metric_period' is ignored for evaluation metric.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bestTest = 0.01423727515\n",
      "bestIteration = 154\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.01571822605\n",
      "bestIteration = 169\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.01299126309\n",
      "bestIteration = 182\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.01518245124\n",
      "bestIteration = 236\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.01571839827\n",
      "bestIteration = 150\n",
      "Training on fold [0/5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Default metric period is 5 because MAE is/are not implemented for GPU\n",
      "Warning: Overfitting detector is active, thus evaluation metric is calculated on every iteration. 'metric_period' is ignored for evaluation metric.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bestTest = 0.01515935243\n",
      "bestIteration = 102\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.01507986104\n",
      "bestIteration = 133\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.01364657045\n",
      "bestIteration = 129\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.01530317587\n",
      "bestIteration = 186\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.01628290871\n",
      "bestIteration = 117\n",
      "Training on fold [0/5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Default metric period is 5 because MAE is/are not implemented for GPU\n",
      "Warning: Overfitting detector is active, thus evaluation metric is calculated on every iteration. 'metric_period' is ignored for evaluation metric.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bestTest = 0.01522983949\n",
      "bestIteration = 147\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.01568498641\n",
      "bestIteration = 85\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.01432242423\n",
      "bestIteration = 71\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.01499200891\n",
      "bestIteration = 91\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.01563652945\n",
      "bestIteration = 78\n",
      "Training on fold [0/5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Default metric period is 5 because MAE is/are not implemented for GPU\n",
      "Warning: Overfitting detector is active, thus evaluation metric is calculated on every iteration. 'metric_period' is ignored for evaluation metric.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bestTest = 0.01448593695\n",
      "bestIteration = 189\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.01464101727\n",
      "bestIteration = 211\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.01327759503\n",
      "bestIteration = 172\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.01504682324\n",
      "bestIteration = 202\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.0145306911\n",
      "bestIteration = 265\n",
      "Training on fold [0/5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Default metric period is 5 because MAE is/are not implemented for GPU\n",
      "Warning: Overfitting detector is active, thus evaluation metric is calculated on every iteration. 'metric_period' is ignored for evaluation metric.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bestTest = 0.01453582202\n",
      "bestIteration = 115\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.01565923574\n",
      "bestIteration = 150\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.0128874691\n",
      "bestIteration = 152\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.01630459826\n",
      "bestIteration = 172\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.01481932475\n",
      "bestIteration = 156\n",
      "Training on fold [0/5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Default metric period is 5 because MAE is/are not implemented for GPU\n",
      "Warning: Overfitting detector is active, thus evaluation metric is calculated on every iteration. 'metric_period' is ignored for evaluation metric.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bestTest = 0.01530143673\n",
      "bestIteration = 34\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.0172917682\n",
      "bestIteration = 32\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.01571158836\n",
      "bestIteration = 40\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.01612858685\n",
      "bestIteration = 36\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.01628875144\n",
      "bestIteration = 41\n",
      "Training on fold [0/5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Default metric period is 5 because MAE is/are not implemented for GPU\n",
      "Warning: Overfitting detector is active, thus evaluation metric is calculated on every iteration. 'metric_period' is ignored for evaluation metric.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bestTest = 0.01479776359\n",
      "bestIteration = 136\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.01480357632\n",
      "bestIteration = 140\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.01335357011\n",
      "bestIteration = 99\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.01519441605\n",
      "bestIteration = 129\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.01505319572\n",
      "bestIteration = 119\n",
      "Training on fold [0/5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Default metric period is 5 because MAE is/are not implemented for GPU\n",
      "Warning: Overfitting detector is active, thus evaluation metric is calculated on every iteration. 'metric_period' is ignored for evaluation metric.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bestTest = 0.02157906374\n",
      "bestIteration = 11\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.02021876288\n",
      "bestIteration = 12\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.01948139565\n",
      "bestIteration = 14\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.01889723503\n",
      "bestIteration = 14\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.02180794728\n",
      "bestIteration = 12\n",
      "Training on fold [0/5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Default metric period is 5 because MAE is/are not implemented for GPU\n",
      "Warning: Overfitting detector is active, thus evaluation metric is calculated on every iteration. 'metric_period' is ignored for evaluation metric.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bestTest = 0.01440022182\n",
      "bestIteration = 142\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.01363573484\n",
      "bestIteration = 228\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.0130721923\n",
      "bestIteration = 165\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.01484803334\n",
      "bestIteration = 276\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.01435163433\n",
      "bestIteration = 244\n",
      "Training on fold [0/5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Default metric period is 5 because MAE is/are not implemented for GPU\n",
      "Warning: Overfitting detector is active, thus evaluation metric is calculated on every iteration. 'metric_period' is ignored for evaluation metric.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bestTest = 0.01419144174\n",
      "bestIteration = 176\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.01474821933\n",
      "bestIteration = 216\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.01298456543\n",
      "bestIteration = 155\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.01490681011\n",
      "bestIteration = 236\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.01452765347\n",
      "bestIteration = 220\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Default metric period is 5 because MAE is/are not implemented for GPU\n",
      "Warning: Overfitting detector is active, thus evaluation metric is calculated on every iteration. 'metric_period' is ignored for evaluation metric.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on fold [0/5]\n",
      "bestTest = 0.01484985586\n",
      "bestIteration = 161\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.01487134278\n",
      "bestIteration = 198\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.0134096248\n",
      "bestIteration = 146\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.01553334634\n",
      "bestIteration = 182\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.01462417767\n",
      "bestIteration = 178\n",
      "Training on fold [0/5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Default metric period is 5 because MAE is/are not implemented for GPU\n",
      "Warning: Overfitting detector is active, thus evaluation metric is calculated on every iteration. 'metric_period' is ignored for evaluation metric.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bestTest = 0.01506478362\n",
      "bestIteration = 124\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.01541225018\n",
      "bestIteration = 111\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.01415110512\n",
      "bestIteration = 98\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.01569035302\n",
      "bestIteration = 129\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.01474778299\n",
      "bestIteration = 96\n",
      "Training on fold [0/5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Default metric period is 5 because MAE is/are not implemented for GPU\n",
      "Warning: Overfitting detector is active, thus evaluation metric is calculated on every iteration. 'metric_period' is ignored for evaluation metric.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bestTest = 0.01435438841\n",
      "bestIteration = 57\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.01630021312\n",
      "bestIteration = 55\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.01397158909\n",
      "bestIteration = 60\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.01663092894\n",
      "bestIteration = 57\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.01622706872\n",
      "bestIteration = 56\n",
      "Training on fold [0/5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Default metric period is 5 because MAE is/are not implemented for GPU\n",
      "Warning: Overfitting detector is active, thus evaluation metric is calculated on every iteration. 'metric_period' is ignored for evaluation metric.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bestTest = 0.01503829722\n",
      "bestIteration = 134\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.01475687992\n",
      "bestIteration = 153\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.01342130146\n",
      "bestIteration = 163\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.0157231758\n",
      "bestIteration = 195\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.01554159618\n",
      "bestIteration = 167\n",
      "Training on fold [0/5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Default metric period is 5 because MAE is/are not implemented for GPU\n",
      "Warning: Overfitting detector is active, thus evaluation metric is calculated on every iteration. 'metric_period' is ignored for evaluation metric.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bestTest = 0.01447006822\n",
      "bestIteration = 130\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.01550637579\n",
      "bestIteration = 178\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.01364473624\n",
      "bestIteration = 119\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.01488080932\n",
      "bestIteration = 211\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.01544325146\n",
      "bestIteration = 185\n",
      "Training on fold [0/5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Default metric period is 5 because MAE is/are not implemented for GPU\n",
      "Warning: Overfitting detector is active, thus evaluation metric is calculated on every iteration. 'metric_period' is ignored for evaluation metric.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bestTest = 0.01465778702\n",
      "bestIteration = 219\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.01519051944\n",
      "bestIteration = 285\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.01309726575\n",
      "bestIteration = 273\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.01594142095\n",
      "bestIteration = 215\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.01423092536\n",
      "bestIteration = 338\n",
      "Training on fold [0/5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Default metric period is 5 because MAE is/are not implemented for GPU\n",
      "Warning: Overfitting detector is active, thus evaluation metric is calculated on every iteration. 'metric_period' is ignored for evaluation metric.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bestTest = 0.0161357906\n",
      "bestIteration = 51\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.01677310394\n",
      "bestIteration = 40\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.01614472032\n",
      "bestIteration = 40\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.01712583472\n",
      "bestIteration = 82\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.01773170189\n",
      "bestIteration = 46\n",
      "Training on fold [0/5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Default metric period is 5 because MAE is/are not implemented for GPU\n",
      "Warning: Overfitting detector is active, thus evaluation metric is calculated on every iteration. 'metric_period' is ignored for evaluation metric.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bestTest = 0.01662804013\n",
      "bestIteration = 59\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.0175597419\n",
      "bestIteration = 70\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.01481795311\n",
      "bestIteration = 31\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.0179448508\n",
      "bestIteration = 37\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.01832910379\n",
      "bestIteration = 36\n",
      "Training on fold [0/5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Default metric period is 5 because MAE is/are not implemented for GPU\n",
      "Warning: Overfitting detector is active, thus evaluation metric is calculated on every iteration. 'metric_period' is ignored for evaluation metric.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bestTest = 0.01447080542\n",
      "bestIteration = 264\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.01434401062\n",
      "bestIteration = 371\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.0120285925\n",
      "bestIteration = 278\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.01450838487\n",
      "bestIteration = 251\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.01534137314\n",
      "bestIteration = 207\n",
      "Training on fold [0/5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Default metric period is 5 because MAE is/are not implemented for GPU\n",
      "Warning: Overfitting detector is active, thus evaluation metric is calculated on every iteration. 'metric_period' is ignored for evaluation metric.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bestTest = 0.01461402916\n",
      "bestIteration = 152\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.01450201631\n",
      "bestIteration = 234\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.01298373609\n",
      "bestIteration = 122\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.01548873281\n",
      "bestIteration = 159\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.01478893816\n",
      "bestIteration = 193\n",
      "Training on fold [0/5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Default metric period is 5 because MAE is/are not implemented for GPU\n",
      "Warning: Overfitting detector is active, thus evaluation metric is calculated on every iteration. 'metric_period' is ignored for evaluation metric.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bestTest = 0.01486254909\n",
      "bestIteration = 271\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.01464910156\n",
      "bestIteration = 356\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.012984504\n",
      "bestIteration = 212\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.01439915259\n",
      "bestIteration = 220\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.01471181122\n",
      "bestIteration = 210\n",
      "Training on fold [0/5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Default metric period is 5 because MAE is/are not implemented for GPU\n",
      "Warning: Overfitting detector is active, thus evaluation metric is calculated on every iteration. 'metric_period' is ignored for evaluation metric.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bestTest = 0.01450966619\n",
      "bestIteration = 213\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.01424554959\n",
      "bestIteration = 371\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.01292158782\n",
      "bestIteration = 240\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.01361456385\n",
      "bestIteration = 528\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.01431884442\n",
      "bestIteration = 334\n",
      "Training on fold [0/5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Default metric period is 5 because MAE is/are not implemented for GPU\n",
      "Warning: Overfitting detector is active, thus evaluation metric is calculated on every iteration. 'metric_period' is ignored for evaluation metric.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bestTest = 0.01432998049\n",
      "bestIteration = 171\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.01456862871\n",
      "bestIteration = 322\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.01269141589\n",
      "bestIteration = 183\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.01490896319\n",
      "bestIteration = 284\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.01515048227\n",
      "bestIteration = 225\n",
      "Training on fold [0/5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Default metric period is 5 because MAE is/are not implemented for GPU\n",
      "Warning: Overfitting detector is active, thus evaluation metric is calculated on every iteration. 'metric_period' is ignored for evaluation metric.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bestTest = 0.01326196472\n",
      "bestIteration = 490\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.01462052936\n",
      "bestIteration = 333\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.01241782399\n",
      "bestIteration = 294\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.01525303923\n",
      "bestIteration = 181\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.01414157432\n",
      "bestIteration = 369\n",
      "Training on fold [0/5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Default metric period is 5 because MAE is/are not implemented for GPU\n",
      "Warning: Overfitting detector is active, thus evaluation metric is calculated on every iteration. 'metric_period' is ignored for evaluation metric.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bestTest = 0.01525025134\n",
      "bestIteration = 231\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.01500032577\n",
      "bestIteration = 259\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.01298046697\n",
      "bestIteration = 266\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.0135301315\n",
      "bestIteration = 608\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.01472735846\n",
      "bestIteration = 255\n",
      "Training on fold [0/5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Default metric period is 5 because MAE is/are not implemented for GPU\n",
      "Warning: Overfitting detector is active, thus evaluation metric is calculated on every iteration. 'metric_period' is ignored for evaluation metric.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bestTest = 0.01553336535\n",
      "bestIteration = 149\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.01445329701\n",
      "bestIteration = 276\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.01320520939\n",
      "bestIteration = 184\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.01524306221\n",
      "bestIteration = 187\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.01583395328\n",
      "bestIteration = 147\n",
      "Training on fold [0/5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Default metric period is 5 because MAE is/are not implemented for GPU\n",
      "Warning: Overfitting detector is active, thus evaluation metric is calculated on every iteration. 'metric_period' is ignored for evaluation metric.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bestTest = 0.01420759862\n",
      "bestIteration = 285\n",
      "Training on fold [1/5]\n",
      "bestTest = 0.01475808079\n",
      "bestIteration = 212\n",
      "Training on fold [2/5]\n",
      "bestTest = 0.01325613004\n",
      "bestIteration = 216\n",
      "Training on fold [3/5]\n",
      "bestTest = 0.01597900917\n",
      "bestIteration = 241\n",
      "Training on fold [4/5]\n",
      "bestTest = 0.01481593391\n",
      "bestIteration = 207\n"
     ]
    }
   ],
   "source": [
    "study_catboost = optuna.create_study(direction='minimize', pruner=optuna.pruners.MedianPruner(n_startup_trials=5, n_warmup_steps=30),study_name='CatBoost_Hyperparameter_Tuning')\n",
    "study_catboost.optimize(objective_catboost_function, n_trials=60, show_progress_bar=True)\n",
    "best_catboost_iterations = study_catboost.best_trial.user_attrs.get('n_estimators_optimal')\n",
    "final_catboost_params = study_catboost.best_params.copy()\n",
    "final_catboost_params['depth'] = final_catboost_params.pop('max_depth')\n",
    "final_catboost_params['l2_leaf_reg'] = final_catboost_params.pop('lambda')\n",
    "final_catboost_params['min_data_in_leaf'] = final_catboost_params.pop('min_child_weight')\n",
    "final_catboost_params.pop('alpha', None)\n",
    "final_catboost_params['loss_function'] = 'MAE'\n",
    "final_catboost_params['eval_metric'] = 'MAE'\n",
    "final_catboost_params['iterations'] = best_catboost_iterations\n",
    "final_catboost_params['task_type'] = 'GPU'\n",
    "final_catboost_params['random_seed'] = 42\n",
    "final_catboost_params['verbose'] = 0\n",
    "best_catboost_model = cb.CatBoostRegressor(**final_catboost_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fdb8ad21",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Default metric period is 5 because MAE is/are not implemented for GPU\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostRegressor at 0x206c0cbc140>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_xgb_model.fit(X_train_transformed, y_train_transformed)\n",
    "best_lgbm_model.fit(X_train_transformed, y_train_transformed)\n",
    "best_catboost_model.fit(X_train_transformed, y_train_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "6c40dd1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "save_path_xgb = \"./model/check_model_xgb_no_geo_no_mediasource_d60.joblib\"\n",
    "save_path_lgbm = \"./model/check_model_lgbm_no_geo_no_mediasource_d60.joblib\"\n",
    "save_path_catboost = \"./model/check_model_catboost_no_geo_no_mediasource_d60.joblib\"\n",
    "#joblib.dump(best_xgb_model, save_path_xgb)\n",
    "#joblib.dump(best_lgbm_model, save_path_lgbm)\n",
    "#joblib.dump(best_catboost_model, save_path_catboost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "a5d152ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_xgb_model = joblib.load(save_path_xgb)\n",
    "best_lgbm_model = joblib.load(save_path_lgbm)\n",
    "best_catboost_model = joblib.load(save_path_catboost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "ae42270a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_nae(y_true_original, y_pred_original, eps=1e-9):\n",
    "    return np.mean(\n",
    "        np.abs(y_true_original - y_pred_original) / (np.abs(y_true_original) + eps)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "1d5eb3ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. NAE XGBoost (gi tr gc): 15.1473%\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] lambda_l1 is set=7.170753391958762e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.170753391958762e-08\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.741545645274762, reg_lambda=0.0 will be ignored. Current value: lambda_l2=6.741545645274762\n",
      "2. NAE LightGBM (gi tr gc): 15.6778%\n",
      "3. NAE CatBoost (gi tr gc): 15.4186%\n"
     ]
    }
   ],
   "source": [
    "y_test_true = preprocessor_y.inverse_transform(\n",
    "    y_test_transformed.values.reshape(-1, 1)\n",
    ").flatten()\n",
    "\n",
    "y_pred_transformed_xgb = best_xgb_model.predict(X_test_transformed) \n",
    "y_pred_original_xgb = preprocessor_y.inverse_transform(\n",
    "    y_pred_transformed_xgb.reshape(-1, 1)\n",
    ").flatten()\n",
    "nae_xgb = calculate_nae(y_test_true, y_pred_original_xgb, eps)\n",
    "\n",
    "print(f\"1. NAE XGBoost (gi tr gc): {nae_xgb * 100:.4f}%\")\n",
    "\n",
    "y_pred_transformed_lgbm = best_lgbm_model.predict(X_test_transformed)\n",
    "y_pred_original_lgbm = preprocessor_y.inverse_transform(\n",
    "    y_pred_transformed_lgbm.reshape(-1, 1)\n",
    ").flatten()\n",
    "nae_lgbm = calculate_nae(y_test_true, y_pred_original_lgbm, eps)\n",
    "\n",
    "print(f\"2. NAE LightGBM (gi tr gc): {nae_lgbm * 100:.4f}%\")\n",
    "\n",
    "y_pred_transformed_cat = best_catboost_model.predict(X_test_transformed)\n",
    "y_pred_original_cat = preprocessor_y.inverse_transform(\n",
    "    y_pred_transformed_cat.reshape(-1, 1)\n",
    ").flatten()\n",
    "nae_cat = calculate_nae(y_test_true, y_pred_original_cat, eps)\n",
    "\n",
    "print(f\"3. NAE CatBoost (gi tr gc): {nae_cat * 100:.4f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d2759206",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_oof_pre(xgb_params, lgbm_params, catboost_params, X, y, cv):\n",
    "    xgb_pre = np.zeros(len(y))\n",
    "    lgbm_pre = np.zeros(len(y))\n",
    "    catboost_pre = np.zeros(len(y))\n",
    "    for train_idx, val_idx in cv.split(X, y):\n",
    "        xgb_fold = xgb.XGBRegressor(**xgb_params)\n",
    "        xgb_fold.fit(X.iloc[train_idx], y.iloc[train_idx],eval_set=[(X.iloc[val_idx], y.iloc[val_idx])],verbose=False)\n",
    "        xgb_pre[val_idx] = xgb_fold.predict(X.iloc[val_idx])\n",
    "\n",
    "        lgbm_fold = lgb.LGBMRegressor(**lgbm_params)\n",
    "        lgbm_fold.fit(X.iloc[train_idx], y.iloc[train_idx],eval_set=[(X.iloc[val_idx], y.iloc[val_idx])])\n",
    "        lgbm_pre[val_idx] = lgbm_fold.predict(X.iloc[val_idx])\n",
    "\n",
    "        catboost_fold = cb.CatBoostRegressor(**catboost_params)\n",
    "        catboost_fold.fit(X.iloc[train_idx], y.iloc[train_idx],eval_set=[(X.iloc[val_idx], y.iloc[val_idx])],verbose=False)\n",
    "        catboost_pre[val_idx] = catboost_fold.predict(X.iloc[val_idx])\n",
    "\n",
    "    return xgb_pre, lgbm_pre, catboost_pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6305781b",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_xgboost_params = best_xgb_model.get_params()\n",
    "final_lightgbm_params = best_lgbm_model.get_params()\n",
    "final_catboost_params = best_catboost_model.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "371c94de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] lambda_l1 is set=7.170753391958762e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.170753391958762e-08\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.741545645274762, reg_lambda=0.0 will be ignored. Current value: lambda_l2=6.741545645274762\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] lambda_l1 is set=7.170753391958762e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.170753391958762e-08\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.741545645274762, reg_lambda=0.0 will be ignored. Current value: lambda_l2=6.741545645274762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000529 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12631\n",
      "[LightGBM] [Info] Number of data points in the train set: 651, number of used features: 58\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] lambda_l1 is set=7.170753391958762e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.170753391958762e-08\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.741545645274762, reg_lambda=0.0 will be ignored. Current value: lambda_l2=6.741545645274762\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 0.198695\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] lambda_l1 is set=7.170753391958762e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.170753391958762e-08\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.741545645274762, reg_lambda=0.0 will be ignored. Current value: lambda_l2=6.741545645274762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Default metric period is 5 because MAE is/are not implemented for GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] lambda_l1 is set=7.170753391958762e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.170753391958762e-08\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.741545645274762, reg_lambda=0.0 will be ignored. Current value: lambda_l2=6.741545645274762\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] lambda_l1 is set=7.170753391958762e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.170753391958762e-08\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.741545645274762, reg_lambda=0.0 will be ignored. Current value: lambda_l2=6.741545645274762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000495 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12628\n",
      "[LightGBM] [Info] Number of data points in the train set: 651, number of used features: 58\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] lambda_l1 is set=7.170753391958762e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.170753391958762e-08\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.741545645274762, reg_lambda=0.0 will be ignored. Current value: lambda_l2=6.741545645274762\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 0.200687\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] lambda_l1 is set=7.170753391958762e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.170753391958762e-08\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.741545645274762, reg_lambda=0.0 will be ignored. Current value: lambda_l2=6.741545645274762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Default metric period is 5 because MAE is/are not implemented for GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] lambda_l1 is set=7.170753391958762e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.170753391958762e-08\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.741545645274762, reg_lambda=0.0 will be ignored. Current value: lambda_l2=6.741545645274762\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] lambda_l1 is set=7.170753391958762e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.170753391958762e-08\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.741545645274762, reg_lambda=0.0 will be ignored. Current value: lambda_l2=6.741545645274762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000545 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12630\n",
      "[LightGBM] [Info] Number of data points in the train set: 651, number of used features: 58\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] lambda_l1 is set=7.170753391958762e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.170753391958762e-08\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.741545645274762, reg_lambda=0.0 will be ignored. Current value: lambda_l2=6.741545645274762\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 0.201101\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] lambda_l1 is set=7.170753391958762e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.170753391958762e-08\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.741545645274762, reg_lambda=0.0 will be ignored. Current value: lambda_l2=6.741545645274762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Default metric period is 5 because MAE is/are not implemented for GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] lambda_l1 is set=7.170753391958762e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.170753391958762e-08\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.741545645274762, reg_lambda=0.0 will be ignored. Current value: lambda_l2=6.741545645274762\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] lambda_l1 is set=7.170753391958762e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.170753391958762e-08\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.741545645274762, reg_lambda=0.0 will be ignored. Current value: lambda_l2=6.741545645274762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000491 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12630\n",
      "[LightGBM] [Info] Number of data points in the train set: 651, number of used features: 58\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] lambda_l1 is set=7.170753391958762e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.170753391958762e-08\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.741545645274762, reg_lambda=0.0 will be ignored. Current value: lambda_l2=6.741545645274762\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 0.201235\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] lambda_l1 is set=7.170753391958762e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.170753391958762e-08\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.741545645274762, reg_lambda=0.0 will be ignored. Current value: lambda_l2=6.741545645274762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Default metric period is 5 because MAE is/are not implemented for GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] lambda_l1 is set=7.170753391958762e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.170753391958762e-08\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.741545645274762, reg_lambda=0.0 will be ignored. Current value: lambda_l2=6.741545645274762\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] lambda_l1 is set=7.170753391958762e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.170753391958762e-08\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.741545645274762, reg_lambda=0.0 will be ignored. Current value: lambda_l2=6.741545645274762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000649 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12634\n",
      "[LightGBM] [Info] Number of data points in the train set: 652, number of used features: 58\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] lambda_l1 is set=7.170753391958762e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.170753391958762e-08\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.741545645274762, reg_lambda=0.0 will be ignored. Current value: lambda_l2=6.741545645274762\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 0.202615\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] lambda_l1 is set=7.170753391958762e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.170753391958762e-08\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.741545645274762, reg_lambda=0.0 will be ignored. Current value: lambda_l2=6.741545645274762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Default metric period is 5 because MAE is/are not implemented for GPU\n"
     ]
    }
   ],
   "source": [
    "oof_pred_xgb, oof_pred_lgbm, oof_pred_cat = get_oof_pre(final_xgboost_params, final_lightgbm_params, final_catboost_params, X_train_transformed, y_train_transformed, cv)\n",
    "\n",
    "X_meta_train = pd.DataFrame({\n",
    "    'meta_xgb': oof_pred_xgb,\n",
    "    'meta_lgbm': oof_pred_lgbm,\n",
    "    'meta_cat': oof_pred_cat\n",
    "})\n",
    "y_meta_train = y_train_transformed.copy()\n",
    "d_train_meta = xgb.DMatrix(X_meta_train, label=y_meta_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e88860ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d24ba4507cdf47c1bf6279101f29df6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "study_meta = optuna.create_study(direction='minimize')\n",
    "study_meta.optimize(lambda trial: objective_xgboost(trial, d_train_meta), n_trials=30, show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "3cf94f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_meta_n_estimators = study_meta.best_trial.user_attrs.get('n_estimators_optimal') \n",
    "final_meta_params = study_meta.best_params.copy()\n",
    "final_meta_params['n_estimators'] = best_meta_n_estimators\n",
    "final_meta_params['objective'] = 'reg:absoluteerror'\n",
    "best_meta_model = xgb.XGBRegressor(**final_meta_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d7a5bda2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBRegressor(alpha=0.0007574585978466054, base_score=None, booster=None,\n",
       "             callbacks=None, colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=0.7623374351943847, device=None,\n",
       "             early_stopping_rounds=None, enable_categorical=False,\n",
       "             eval_metric=None, feature_types=None, feature_weights=None,\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, lambda=1.0052413077948323e-08,\n",
       "             learning_rate=0.01814556052450437, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=3, max_leaves=None,\n",
       "             min_child_weight=2, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=np.int64(451), ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>XGBRegressor</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.0.0/python/python_api.html#xgboost.XGBRegressor\">?<span>Documentation for XGBRegressor</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>XGBRegressor(alpha=0.0007574585978466054, base_score=None, booster=None,\n",
       "             callbacks=None, colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=0.7623374351943847, device=None,\n",
       "             early_stopping_rounds=None, enable_categorical=False,\n",
       "             eval_metric=None, feature_types=None, feature_weights=None,\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, lambda=1.0052413077948323e-08,\n",
       "             learning_rate=0.01814556052450437, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=3, max_leaves=None,\n",
       "             min_child_weight=2, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=np.int64(451), ...)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "XGBRegressor(alpha=0.0007574585978466054, base_score=None, booster=None,\n",
       "             callbacks=None, colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=0.7623374351943847, device=None,\n",
       "             early_stopping_rounds=None, enable_categorical=False,\n",
       "             eval_metric=None, feature_types=None, feature_weights=None,\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, lambda=1.0052413077948323e-08,\n",
       "             learning_rate=0.01814556052450437, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=3, max_leaves=None,\n",
       "             min_child_weight=2, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=np.int64(451), ...)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_meta_model.fit(X_meta_train, y_meta_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "094cb48e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] lambda_l1 is set=7.170753391958762e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.170753391958762e-08\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.741545645274762, reg_lambda=0.0 will be ignored. Current value: lambda_l2=6.741545645274762\n",
      "NAE tp test (Gi tr gc, Ensemble): 15.3702%\n"
     ]
    }
   ],
   "source": [
    "pred_xgb_test = best_xgb_model.predict(X_test_transformed)\n",
    "pred_lgbm_test = best_lgbm_model.predict(X_test_transformed)\n",
    "pred_catboost_test = best_catboost_model.predict(X_test_transformed)\n",
    "X_meta_test = np.column_stack([\n",
    "    pred_xgb_test.flatten(),\n",
    "    pred_lgbm_test.flatten(),\n",
    "    pred_catboost_test.flatten()\n",
    "])\n",
    "pred_meta = best_meta_model.predict(X_meta_test)\n",
    "\n",
    "y_test_true = preprocessor_y.inverse_transform(\n",
    "    y_test_transformed.values.reshape(-1, 1)\n",
    ").flatten()\n",
    "\n",
    "final_prediction = preprocessor_y.inverse_transform(\n",
    "    pred_meta.reshape(-1, 1)\n",
    ").flatten()\n",
    "\n",
    "nae = np.mean(\n",
    "    np.abs(y_test_true - final_prediction) / (np.abs(y_test_true) + eps)\n",
    ")\n",
    "\n",
    "print(f\"NAE tp test (Gi tr gc, Ensemble): {nae * 100:.4f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce8dd04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_oof_res(meta_params, X, y, cv):\n",
    "    residuals = np.zeros(len(y))\n",
    "    meta_pre = np.zeros(len(y))\n",
    "    for train_idx, val_idx in cv.split(X, y):\n",
    "        meta_fold = xgb.XGBRegressor(**meta_params)\n",
    "        meta_fold.fit(X.iloc[train_idx], y.iloc[train_idx],eval_set=[(X.iloc[val_idx], y.iloc[val_idx])],verbose=False)\n",
    "        pred = meta_fold.predict(X.iloc[val_idx])\n",
    "        meta_pre[val_idx] = meta_fold.predict(X.iloc[val_idx])\n",
    "        residuals[val_idx] = y.iloc[val_idx].values.flatten() - pred.flatten()\n",
    "\n",
    "    return residuals, meta_pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db10dbd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals, meta_oof = get_oof_res(final_meta_params, X_meta_train, y_meta_train, cv)\n",
    "X_res_train = X_meta_train.copy()\n",
    "meta_cols = ['meta_xgb', 'meta_lgbm', 'meta_cat']\n",
    "X_res_train['meta_mean'] = X_res_train[meta_cols].mean(axis=1)\n",
    "X_res_train['meta_std'] = X_res_train[meta_cols].std(axis=1)\n",
    "X_res_train['range'] = X_res_train[meta_cols].max(axis=1) - X_res_train[meta_cols].min(axis=1)\n",
    "X_res_train['meta_oof'] = meta_oof\n",
    "y_res_train = pd.DataFrame({'residual': residuals})\n",
    "d_train_res = xgb.DMatrix(X_res_train, label=y_res_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e25567cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de53d722de9941959023c98b0cfa1fb5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "study_res = optuna.create_study(direction='minimize')\n",
    "study_res.optimize(lambda trial: objective_xgboost(trial, d_train_res), n_trials=30, show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "9d1c0b47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-2 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-2 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-2 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-2 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-2 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBRegressor(alpha=0.00641032818740841, base_score=None, booster=None,\n",
       "             callbacks=None, colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=0.8965192884395705, device=None,\n",
       "             early_stopping_rounds=None, enable_categorical=False,\n",
       "             eval_metric=None, feature_types=None, feature_weights=None,\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, lambda=0.002081021069938392,\n",
       "             learning_rate=0.016706153588729417, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=3, max_leaves=None,\n",
       "             min_child_weight=3, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=np.int64(753), ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>XGBRegressor</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.0.0/python/python_api.html#xgboost.XGBRegressor\">?<span>Documentation for XGBRegressor</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>XGBRegressor(alpha=0.00641032818740841, base_score=None, booster=None,\n",
       "             callbacks=None, colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=0.8965192884395705, device=None,\n",
       "             early_stopping_rounds=None, enable_categorical=False,\n",
       "             eval_metric=None, feature_types=None, feature_weights=None,\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, lambda=0.002081021069938392,\n",
       "             learning_rate=0.016706153588729417, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=3, max_leaves=None,\n",
       "             min_child_weight=3, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=np.int64(753), ...)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "XGBRegressor(alpha=0.00641032818740841, base_score=None, booster=None,\n",
       "             callbacks=None, colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=0.8965192884395705, device=None,\n",
       "             early_stopping_rounds=None, enable_categorical=False,\n",
       "             eval_metric=None, feature_types=None, feature_weights=None,\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, lambda=0.002081021069938392,\n",
       "             learning_rate=0.016706153588729417, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=3, max_leaves=None,\n",
       "             min_child_weight=3, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=np.int64(753), ...)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_res_n_estimators = study_res.best_trial.user_attrs.get('n_estimators_optimal') \n",
    "final_res_params = study_res.best_params.copy()\n",
    "final_res_params['n_estimators'] = best_res_n_estimators\n",
    "final_res_params['objective'] = 'reg:absoluteerror'\n",
    "best_res_model = xgb.XGBRegressor(**final_res_params)\n",
    "best_res_model.fit(X_res_train, y_res_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "745998ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_weight_residual(y_true_orig, yA_t, yBres_t, preY):\n",
    "    def loss(w_arr):\n",
    "        w = float(np.asarray(w_arr).item())\n",
    "        y_pred_t = yA_t + w * yBres_t\n",
    "        y_pred = preY.inverse_transform(y_pred_t.reshape(-1,1)).ravel()\n",
    "        return nae(y_true_orig, y_pred)\n",
    "\n",
    "    res = minimize(loss, x0=[0.5], bounds=[(0, 1)], method=\"L-BFGS-B\")\n",
    "    return float(res.x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ebf436",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_xgb_vali = best_xgb_model.predict(X_vali_transformed).flatten()\n",
    "pred_lgbm_vali = best_lgbm_model.predict(X_vali_transformed).flatten()\n",
    "pred_catboost_vali = best_catboost_model.predict(X_vali_transformed).flatten()\n",
    "y_vali_orig = preprocessor_y.inverse_transform(y_vali_transformed.values.reshape(-1,1)).ravel()\n",
    "\n",
    "X_meta_vali = pd.DataFrame({\n",
    "    'meta_xgb': pred_xgb_vali,\n",
    "    'meta_lgbm': pred_lgbm_vali,\n",
    "    'meta_cat': pred_catboost_vali\n",
    "})\n",
    "\n",
    "meta_cols = ['meta_xgb', 'meta_lgbm', 'meta_cat']\n",
    "X_meta_test_base = np.column_stack([\n",
    "    pred_xgb_vali,\n",
    "    pred_lgbm_vali,\n",
    "    pred_catboost_vali\n",
    "])\n",
    "pred_meta_vali = best_meta_model.predict(X_meta_test_base)\n",
    "meta_mean_vali = X_meta_vali[meta_cols].mean(axis=1)\n",
    "meta_std_vali = X_meta_vali[meta_cols].std(axis=1)\n",
    "meta_range_vali = X_meta_vali[meta_cols].max(axis=1) - X_meta_vali[meta_cols].min(axis=1)\n",
    "\n",
    "X_res_vali_final = np.column_stack([\n",
    "    pred_xgb_vali,\n",
    "    pred_lgbm_vali,\n",
    "    pred_catboost_vali,\n",
    "    meta_mean_vali,\n",
    "    meta_std_vali,\n",
    "    meta_range_vali,\n",
    "    pred_meta_vali\n",
    "])\n",
    "\n",
    "pred_res_vali = best_res_model.predict(X_res_vali_final)\n",
    "w = find_best_weight_residual(y_vali_orig, pred_meta_vali, pred_res_vali, preprocessor_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c8a6f5fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] lambda_l1 is set=7.170753391958762e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.170753391958762e-08\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.741545645274762, reg_lambda=0.0 will be ignored. Current value: lambda_l2=6.741545645274762\n",
      "NAE tp test (Gi tr gc, res): 15.4700%\n"
     ]
    }
   ],
   "source": [
    "pred_xgb_test = best_xgb_model.predict(X_test_transformed).flatten()\n",
    "pred_lgbm_test = best_lgbm_model.predict(X_test_transformed).flatten()\n",
    "pred_catboost_test = best_catboost_model.predict(X_test_transformed).flatten()\n",
    "\n",
    "X_meta_temp = pd.DataFrame({\n",
    "    'meta_xgb': pred_xgb_test,\n",
    "    'meta_lgbm': pred_lgbm_test,\n",
    "    'meta_cat': pred_catboost_test\n",
    "})\n",
    "\n",
    "meta_cols = ['meta_xgb', 'meta_lgbm', 'meta_cat']\n",
    "X_meta_test_base = np.column_stack([\n",
    "    pred_xgb_test,\n",
    "    pred_lgbm_test,\n",
    "    pred_catboost_test\n",
    "])\n",
    "pred_meta_as_feature = best_meta_model.predict(X_meta_test_base)\n",
    "meta_mean_test = X_meta_temp[meta_cols].mean(axis=1)\n",
    "meta_std_test = X_meta_temp[meta_cols].std(axis=1)\n",
    "meta_range_test = X_meta_temp[meta_cols].max(axis=1) - X_meta_temp[meta_cols].min(axis=1)\n",
    "\n",
    "X_res_test_final = np.column_stack([\n",
    "    pred_xgb_test,\n",
    "    pred_lgbm_test,\n",
    "    pred_catboost_test,\n",
    "    meta_mean_test,\n",
    "    meta_std_test,\n",
    "    meta_range_test,\n",
    "    pred_meta_as_feature\n",
    "])\n",
    "\n",
    "pred_meta = best_res_model.predict(X_res_test_final)\n",
    "\n",
    "y_test_true = preprocessor_y.inverse_transform(\n",
    "    y_test_transformed.values.reshape(-1, 1)\n",
    ").flatten()\n",
    "\n",
    "final_prediction = preprocessor_y.inverse_transform(\n",
    "    pred_meta.reshape(-1, 1)\n",
    ").flatten()\n",
    "\n",
    "nae = calculate_nae(y_test_true, final_prediction, eps)\n",
    "\n",
    "print(f\"NAE tp test (Gi tr gc, res): {nae * 100:.4f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "3e063cee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
      "[LightGBM] [Warning] lambda_l1 is set=7.170753391958762e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.170753391958762e-08\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.741545645274762, reg_lambda=0.0 will be ignored. Current value: lambda_l2=6.741545645274762\n",
      "NAE tp kim th (Gi tr gc): 9.2493%\n"
     ]
    }
   ],
   "source": [
    "pred_xgb_infer = best_xgb_model.predict(X_infer_transformed).flatten()\n",
    "pred_lgbm_infer = best_lgbm_model.predict(X_infer_transformed).flatten()\n",
    "pred_catboost_infer = best_catboost_model.predict(X_infer_transformed).flatten()\n",
    "\n",
    "X_meta_temp = pd.DataFrame({\n",
    "    'meta_xgb': pred_xgb_infer,\n",
    "    'meta_lgbm': pred_lgbm_infer,\n",
    "    'meta_cat': pred_catboost_infer\n",
    "})\n",
    "\n",
    "meta_cols = ['meta_xgb', 'meta_lgbm', 'meta_cat']\n",
    "X_meta_infer_base = np.column_stack([\n",
    "    pred_xgb_infer,\n",
    "    pred_lgbm_infer,\n",
    "    pred_catboost_infer\n",
    "])\n",
    "pred_meta_as_feature = best_meta_model.predict(X_meta_infer_base)\n",
    "meta_mean_infer = X_meta_temp[meta_cols].mean(axis=1)\n",
    "meta_std_infer = X_meta_temp[meta_cols].std(axis=1)\n",
    "meta_range_infer = X_meta_temp[meta_cols].max(axis=1) - X_meta_temp[meta_cols].min(axis=1)\n",
    "\n",
    "X_res_infer_final = np.column_stack([\n",
    "    pred_xgb_infer,\n",
    "    pred_lgbm_infer,\n",
    "    pred_catboost_infer,\n",
    "    meta_mean_infer,\n",
    "    meta_std_infer,\n",
    "    meta_range_infer,\n",
    "    pred_meta_as_feature\n",
    "])\n",
    "\n",
    "pred_meta_infer = best_res_model.predict(X_res_infer_final)\n",
    "\n",
    "y_infer_true = preprocessor_y.inverse_transform(\n",
    "    y_infer_transformed.values.reshape(-1, 1)\n",
    ").flatten()\n",
    "\n",
    "final_prediction = preprocessor_y.inverse_transform(\n",
    "    pred_meta_infer.reshape(-1, 1)\n",
    ").flatten()\n",
    "\n",
    "nae = calculate_nae(y_infer_true, final_prediction, eps)\n",
    "\n",
    "print(f\"NAE tp kim th (Gi tr gc): {nae * 100:.4f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b162bf52",
   "metadata": {},
   "source": [
    "NAE tp kim th (Gi tr gc): 9.2493%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5102f3d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e618ff4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba662afc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "ad1fc677",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./model/ltv_d60_stack_pipeline.joblib']"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "artifacts = {\n",
    "  \"power_X\": preprocessor_X,\n",
    "  \"power_y\": preprocessor_y,\n",
    "  \"feature_list\": X_train_transformed.columns.tolist(),\n",
    "  \"oof_predict_models\": oof_predcit_models,\n",
    "  \"base_models\": {\n",
    "      \"xgb\": best_xgb_model, \"lgbm\": best_lgbm_model, \"cat\": best_catboost_model\n",
    "  },\n",
    "  \"randomstate\" : 42,\n",
    "  \"meta_model\": best_meta_model,\n",
    "  \"residual_model\": best_res_model\n",
    "}\n",
    "joblib.dump(artifacts, \"./model/ltv_d60_stack_pipeline.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ec472a",
   "metadata": {},
   "outputs": [],
   "source": [
    "arti = joblib.load(\"./model/ltv_d60_stack_pipeline.joblib\")\n",
    "best_meta_model = arti['meta_model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "770d7810",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed1d049e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b9b8b8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "explainer = shap.TreeExplainer(best_xgb_model)\n",
    "shap_values = explainer.shap_values(X_train_transformed) \n",
    "\n",
    "shap_importance = np.abs(shap_values).mean(axis=0)\n",
    "features = X_train_transformed.columns.tolist()\n",
    "\n",
    "feature_importance_df = pd.DataFrame({\n",
    "    'feature': features,\n",
    "    'importance': shap_importance\n",
    "}).sort_values(by='importance', ascending=False) \n",
    "\n",
    "top_n = 60\n",
    "best_features = feature_importance_df['feature'].head(top_n).tolist()\n",
    "\n",
    "all_features = X_train_transformed.columns.tolist()\n",
    "unimportant_features_to_drop = list(set(all_features) - set(best_features))\n",
    "\n",
    "X_train_transformed = X_train_transformed.drop(columns=unimportant_features_to_drop)\n",
    "X_test_transformed = X_test_transformed.drop(columns=unimportant_features_to_drop)\n",
    "\n",
    "unimportant_features_to_drop"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
